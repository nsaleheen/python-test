{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in the training data: 80341\n",
      "Number of observations in the test data: 80582\n",
      "Index(['mean', 'median', 'sd', 'sd_x', 'sd_y', 'sd_z', 'skew', 'kurt',\n",
      "       'rateOfChange'],\n",
      "      dtype='object')\n",
      "0.837804968852\n",
      "Predicted labels  HIGH    LOW  MODERATE  NO_ACT\n",
      "Actual labels                                  \n",
      "HIGH              3787    793       231     149\n",
      "LOW                177  19320       815    4408\n",
      "MODERATE           271   2889      2686     341\n",
      "NO_ACT              22   2929        45   41719\n",
      "[('mean', 0.096187667507750554), ('median', 0.082364166409655049), ('sd', 0.12300186493020697), ('sd_x', 0.12530415518749297), ('sd_y', 0.20882691941285728), ('sd_z', 0.16294741981645075), ('skew', 0.069984093695550836), ('kurt', 0.080948364019944735), ('rateOfChange', 0.050435349020090864)]\n",
      "0.837804968852\n",
      "Predicted labels  HIGH    LOW  MODERATE  NO_ACT\n",
      "Actual labels                                  \n",
      "HIGH              3787    793       231     149\n",
      "LOW                177  19320       815    4408\n",
      "MODERATE           271   2889      2686     341\n",
      "NO_ACT              22   2929        45   41719\n",
      "      0      1     2      3\n",
      "0  3787    793   231    149\n",
      "1   177  19320   815   4408\n",
      "2   271   2889  2686    341\n",
      "3    22   2929    45  41719\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       HIGH       0.89      0.76      0.82      4960\n",
      "        LOW       0.75      0.78      0.76     24720\n",
      "   MODERATE       0.71      0.43      0.54      6187\n",
      "     NO_ACT       0.89      0.93      0.91     44715\n",
      "\n",
      "avg / total       0.83      0.84      0.83     80582\n",
      "\n",
      "(0.83451425531046319, 0.8378049688516046, 0.83293772508182518, None)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-4f5a1b3077c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabelName\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# homes = pd.read_csv('C:/Research/Data/Activity/Extrasensory-activity-featurefile-all_1000.csv')\n",
    "homes = pd.read_csv('C:/Research/Data/Activity/streamprocessor-like-data-25hz/featureFile.csv')\n",
    "\n",
    "homes['is_train'] = np.random.uniform(0, 1, len(homes)) <= .50\n",
    "df = homes\n",
    "\n",
    "train, test = df[df['is_train']==True], df[df['is_train']==False]\n",
    "\n",
    "print('Number of observations in the training data:', len(train))\n",
    "print('Number of observations in the test data:',len(test))\n",
    "\n",
    "features = df.columns[:9]\n",
    "\n",
    "print(features)\n",
    "\n",
    "labelName = 'activityLabel'\n",
    "# labelName = 'actualActivity'\n",
    "\n",
    "\n",
    "y=train[labelName]\n",
    "#y = pd.factorize(train[labelName])[0]\n",
    "\n",
    "# Create a random forest Classifier. By convention, clf means 'Classifier'\n",
    "clf = RandomForestClassifier(n_jobs=2, random_state=0, n_estimators=100)\n",
    "\n",
    "# Train the Classifier to take the training features and learn how they relate\n",
    "# to the training y (the species)\n",
    "clf.fit(train[features], y)\n",
    "\n",
    "preds=clf.predict(test[features])\n",
    "accuracy = accuracy_score(test[labelName], preds)\n",
    "\n",
    "print(accuracy)\n",
    "\n",
    "print(pd.crosstab(test[labelName], preds, rownames=['Actual labels'], colnames=['Predicted labels']))\n",
    "\n",
    "\n",
    "# View a list of the features and their importance scores\n",
    "print(list(zip(train[features], clf.feature_importances_)))\n",
    "\n",
    "\n",
    "filename = 'activity_randomforest.model'\n",
    "pickle.dump(clf, open(filename, 'wb'))\n",
    "\n",
    "# load the model from disk\n",
    "clf = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "preds=clf.predict(test[features])\n",
    "accuracy = accuracy_score(test[labelName], preds)\n",
    "\n",
    "print(accuracy)\n",
    "\n",
    "\n",
    "# Create confusion matrix\n",
    "print(pd.crosstab(test[labelName], preds, rownames=['Actual labels'], colnames=['Predicted labels']))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = pd.DataFrame(confusion_matrix(test[labelName], preds))\n",
    "print(cm)\n",
    "\n",
    "print(classification_report(test[labelName], preds))\n",
    "print(precision_recall_fscore_support(test[labelName], preds, average='weighted'))\n",
    "\n",
    "sns.heatmap(cm)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://www.blopig.com/blog/2017/07/using-random-forests-in-python-with-scikit-learn/\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def test_classifier(x_test):\n",
    "    filename = 'activity_randomforest.model'\n",
    "    # load the model from disk\n",
    "    clf = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "    preds=clf.predict(x_test)\n",
    "    \n",
    "    return preds\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "        \n",
    "    homes = pd.read_csv('C:/Research/Data/Activity/Extrasensory-activity-featurefile-all_1000.csv')\n",
    "    homes['is_train'] = np.random.uniform(0, 1, len(homes)) <= .50\n",
    "    df = homes\n",
    "\n",
    "    train, test = df[df['is_train']==True], df[df['is_train']==False]\n",
    "\n",
    "    print('Number of observations in the training data:', len(train))\n",
    "    print('Number of observations in the test data:',len(test))\n",
    "\n",
    "    features = df.columns[:9]\n",
    "\n",
    "    print(features)\n",
    "\n",
    "    labelName = 'activityLabel'\n",
    "    # labelName = 'actualActivity'\n",
    "\n",
    "\n",
    "    preds=test_classifier(test[features])\n",
    "    accuracy = accuracy_score(test[labelName], preds)\n",
    "\n",
    "    print(accuracy)\n",
    "\n",
    "    print(pd.crosstab(test[labelName], preds, rownames=['Actual labels'], colnames=['Predicted labels']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.DataFrame({ 'x':range(30) })\n",
    "df = df.rolling(10).mean()           # version 0.18.0 syntax\n",
    "df[4::5] \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 1043.25647853\n",
      "Meadian: 1029.82032574\n",
      "Std: 165.276900025\n",
      "Std_x 290.77942005529263\n",
      "Std_y 192.7942452284006\n",
      "Std_z 246.86004424215537\n",
      "Skewness: [ 0.63743938]\n",
      "Kurtosis: [ 1.17167717]\n",
      "roc: [ 0.04478513]\n",
      "features: [[[80.027578897503503, 10091.893100184201, 1043.2564785318309, 1029.8203257362575, 165.27690002463947, 290.77942005529263, 192.7942452284006, 246.86004424215537, array([ 0.63743938]), array([ 1.17167717]), array([ 0.04478513])]]]\n",
      "Mean: 1023.00483177\n",
      "Meadian: 1022.99991651\n",
      "Std: 10.5742416064\n",
      "Std_x 13.008628927128415\n",
      "Std_y 13.192250528858837\n",
      "Std_z 37.669829284571236\n",
      "Skewness: [-0.00368798]\n",
      "Kurtosis: [ 0.40933366]\n",
      "roc: [ 0.00383555]\n",
      "features: [[[80.027578897503503, 10091.893100184201, 1043.2564785318309, 1029.8203257362575, 165.27690002463947, 290.77942005529263, 192.7942452284006, 246.86004424215537, array([ 0.63743938]), array([ 1.17167717]), array([ 0.04478513])]], [[10154.2414104371, 20171.910250978799, 1023.0048317692793, 1022.999916514073, 10.574241606406515, 13.008628927128415, 13.192250528858837, 37.669829284571236, array([-0.00368798]), array([ 0.40933366]), array([ 0.00383555])]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import math\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "def getRateOfChange(timestamp, magnitude):\n",
    "    roc = 0;    \n",
    "    for i in range(len(magnitude)-1):                \n",
    "        roc = roc + (((magnitude[i+1] - magnitude[i]) / (timestamp.iloc[i+1] - timestamp.iloc[i])));\n",
    "    roc = roc / (len(magnitude)- 1);\n",
    "    \n",
    "#     print(\"roc:\",roc);\n",
    "    \n",
    "    return roc\n",
    "\n",
    "def computeFeatures(start_time, end_time, time, x, y, z):\n",
    "    \n",
    "#     print(\"start_time:\", start_time)\n",
    "#     print(\"end_time:\", end_time)\n",
    "#     print(\"time:\",time)\n",
    "#     print(\"x:\",x)\n",
    "#     print(\"y:\",y)\n",
    "#     print(\"z:\",z)\n",
    "            \n",
    "    \n",
    "    mag = np.empty([len(x), 1])\n",
    "    for i in range(len(x)):\n",
    "        mag[i] = math.sqrt(x.iloc[i]*x.iloc[i] + y.iloc[i]*y.iloc[i]+z.iloc[i]*z.iloc[i])\n",
    "\n",
    "    #a = [2, 8, 0, 4, 1, 9, 9, 0];\n",
    "    mean =  np.mean(mag);\n",
    "    median = np.median(mag);\n",
    "    std = np.std(mag);\n",
    "    std_x = np.std(x);\n",
    "    std_y = np.std(y);\n",
    "    std_z = np.std(z);\n",
    "    skewness = skew(mag);\n",
    "    kurt = kurtosis(mag);\n",
    "    \n",
    "    print(\"Mean:\", mean);\n",
    "    print(\"Meadian:\",median);\n",
    "    print(\"Std:\", std);\n",
    "    print(\"Std_x\",std_x);\n",
    "    print(\"Std_y\", std_y);\n",
    "    print(\"Std_z\",std_z);\n",
    "    print(\"Skewness:\",skewness);\n",
    "    print(\"Kurtosis:\",kurt);\n",
    "    \n",
    "    rateOfChanges=getRateOfChange(time, mag)\n",
    "    \n",
    "    f = [start_time, end_time,mean, median, std, std_x, std_y, std_z, skewness, kurt, rateOfChanges]\n",
    "#     print(\"f:\", f)\n",
    "    return f\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    column_names = ['timestamp', 'A_x', 'A_y', 'A_z']\n",
    "    D = pd.read_csv('C:/Research/Data/Activity/right-wrist-accelxyz.csv', names = column_names)\n",
    "    \n",
    "    x= D['A_x']\n",
    "    y= D['A_y']\n",
    "    z= D['A_z']\n",
    "    time= D['timestamp']\n",
    "    \n",
    "    time_prev = time[0]\n",
    "    prev = 0\n",
    "    f_all = []\n",
    "    for i in range(len(time)):\n",
    "        if (time[i] - time_prev) >= 10000:\n",
    "           # print(time[i])\n",
    "           # print(time_prev)\n",
    "            time_sub = time[prev:i+1]\n",
    "            x_sub = x[prev:i+1]\n",
    "            y_sub = y[prev:i+1]\n",
    "            z_sub = z[prev:i+1]\n",
    "            #print(\"time_sub:\",time_sub)\n",
    "            #print(\"x_sub:\",x_sub)\n",
    "            #print(\"y_sub:\",y_sub)\n",
    "            #print(\"z_sub:\",z_sub)\n",
    "            \n",
    "            \n",
    "            features =  computeFeatures(time_prev, time[i], time_sub, x_sub, y_sub, z_sub)\n",
    "           # print(features)\n",
    "            \n",
    "            f_all.append([features])\n",
    "            print(\"features:\", f_all )\n",
    "            \n",
    "            time_prev = time[i+1]\n",
    "            prev = i+1\n",
    "            #print(time_prev)\n",
    "            \n",
    "    \n",
    "    \n",
    "\n",
    "#     print(D.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import math\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "def getRateOfChange(timestamp, magnitude):\n",
    "    roc = 0;    \n",
    "    for i in range(len(magnitude)-1):                \n",
    "        roc = roc + (((magnitude[i+1] - magnitude[i]) / (timestamp.iloc[i+1] - timestamp.iloc[i])));\n",
    "    roc = roc / (len(magnitude)- 1);\n",
    "    \n",
    "    return roc\n",
    "\n",
    "def computeFeatures(ts, x, y, z):\n",
    "    mag = np.empty([len(x), 1])\n",
    "    for i in range(len(x)):\n",
    "        mag[i] = math.sqrt(x.iloc[i]*x.iloc[i] + y.iloc[i]*y.iloc[i]+z.iloc[i]*z.iloc[i])\n",
    "\n",
    "    #a = [2, 8, 0, 4, 1, 9, 9, 0];\n",
    "    mean =  np.mean(mag);\n",
    "    median = np.median(mag);\n",
    "    std = np.std(mag);\n",
    "    std_x = np.std(x);\n",
    "    std_y = np.std(y);\n",
    "    std_z = np.std(z);\n",
    "    skewness = skew(mag);\n",
    "    kurt = kurtosis(mag);\n",
    "    rateOfChanges=getRateOfChange(ts, mag)\n",
    "    \n",
    "    f = [mean, median, std, std_x, std_y, std_z, skewness, kurt, rateOfChanges]\n",
    "    return f\n",
    "\n",
    "def computeWindowFeatures(ts, x, y, z, window_size):\n",
    "    time_prev = ts[0]\n",
    "    prev = 0\n",
    "    features_all = []\n",
    "    for i in range(len(ts)):\n",
    "        if (ts[i] - time_prev) >= window_size:\n",
    "            time_sub = ts[prev:i+1]\n",
    "            x_sub = x[prev:i+1]\n",
    "            y_sub = y[prev:i+1]\n",
    "            z_sub = z[prev:i+1]\n",
    "            features =  computeFeatures(time_sub, x_sub, y_sub, z_sub)\n",
    "            \n",
    "            features_all.append(features)\n",
    "            time_prev = ts[i+1]\n",
    "            prev = i+1\n",
    "    return features_all\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    column_names = ['timestamp', 'A_x', 'A_y', 'A_z']\n",
    "    D = pd.read_csv('C:/Research/Data/Activity/right-wrist-accelxyz.csv', names = column_names)\n",
    "    \n",
    "    x= D['A_x']\n",
    "    y= D['A_y']\n",
    "    z= D['A_z']\n",
    "    ts= D['timestamp']\n",
    "    \n",
    "    features = computeWindowFeatures(ts, x, y, z, window_size=10*1000)\n",
    "    \n",
    "    print(len(features))\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BICYCLING\n",
      "CLEANING\n",
      "COMPUTER WORK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COOKING\n",
      "DOING LAUNDRY\n",
      "EATING\n",
      "exercise\n",
      "LAB WORK\n",
      "LYING DOWN\n",
      "running\n",
      "SHOPPING\n",
      "SLEEPING\n",
      "STAIRS - GOING DOWN\n",
      "STAIRS - GOING UP\n",
      "STROLLING\n",
      "walking\n",
      "WASHING DISHES\n",
      "WATCHING TV\n",
      "160947\n",
      "160947\n",
      "160947\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np, pandas as pd\n",
    "import math\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "def getRateOfChange(timestamp, magnitude):\n",
    "    roc = 0;    \n",
    "    for i in range(len(magnitude)-1):                \n",
    "        roc = roc + (((magnitude[i+1] - magnitude[i]) / (timestamp.iloc[i+1] - timestamp.iloc[i])));\n",
    "    roc = roc / (len(magnitude)- 1);\n",
    "    \n",
    "    return roc\n",
    "\n",
    "def computeFeatures(ts, x, y, z):\n",
    "    mag = np.empty([len(x), 1])\n",
    "    for i in range(len(x)):\n",
    "        mag[i] = math.sqrt(x.iloc[i]*x.iloc[i] + y.iloc[i]*y.iloc[i]+z.iloc[i]*z.iloc[i])\n",
    "\n",
    "    #a = [2, 8, 0, 4, 1, 9, 9, 0];\n",
    "    mean =  np.mean(mag);\n",
    "    median = np.median(mag);\n",
    "    std = np.std(mag);\n",
    "    std_x = np.std(x);\n",
    "    std_y = np.std(y);\n",
    "    std_z = np.std(z);\n",
    "    skewness = skew(mag);\n",
    "    kurt = kurtosis(mag);\n",
    "    rateOfChanges=getRateOfChange(ts, mag)\n",
    "    \n",
    "    f = [mean, median, std, std_x, std_y, std_z, skewness[0], kurt[0], rateOfChanges[0]]\n",
    "    return f\n",
    "\n",
    "def computeWindowFeatures(ts, x, y, z, window_size):\n",
    "    time_prev = ts[0]\n",
    "    prev = 0\n",
    "    features_all = []\n",
    "    for i in range(len(ts)):\n",
    "        if (ts[i] - time_prev) >= window_size:\n",
    "            time_sub = ts[prev:i+1]\n",
    "            x_sub = x[prev:i+1]\n",
    "            y_sub = y[prev:i+1]\n",
    "            z_sub = z[prev:i+1]\n",
    "            features =  computeFeatures(time_sub, x_sub, y_sub, z_sub)\n",
    "            \n",
    "            features_all.append(features)\n",
    "            time_prev = ts[i+1]\n",
    "            prev = i+1\n",
    "    return features_all\n",
    "\n",
    "\n",
    "def getActivityLevelmap():\n",
    "    NO_ACT = 'NO_ACT';\n",
    "    LOW = 'LOW';\n",
    "    MOD = 'MODERATE';\n",
    "    HIGH = 'HIGH';\n",
    "    \n",
    "    M = dict()\n",
    "\n",
    "    M['LYING DOWN'] = NO_ACT\n",
    "    M['SLEEPING'] = NO_ACT\n",
    "    M['CLEANING'] = LOW\n",
    "    M['COMPUTER WORK'] = LOW\n",
    "    M['COOKING'] = LOW\n",
    "    M['DOING LAUNDRY'] = LOW\n",
    "    M['EATING'] = LOW\n",
    "    M['LAB WORK'] = LOW\n",
    "    M['SHOPPING'] = LOW\n",
    "    M['WASHING DISHES'] = LOW\n",
    "    M['WATCHING TV'] = LOW\n",
    "    M['STAIRS - GOING DOWN'] = MOD\n",
    "    M['STAIRS - GOING UP'] = MOD\n",
    "    M['STROLLING'] = MOD\n",
    "    M['walking'] = MOD\n",
    "    M['exercise'] = HIGH\n",
    "    M['running'] = HIGH\n",
    "    M['BICYCLING'] = HIGH\n",
    "    \n",
    "    return M\n",
    "\n",
    "\n",
    "# [x[0] for x in os.walk(directory)]\n",
    "if __name__ == \"__main__\":\n",
    "    dirName = 'C:/Research/Data/Activity/streamprocessor-like-data-25hz/'\n",
    "    filename = 'right-wrist-accelxyz.csv'\n",
    "    column_names = ['timestamp', 'A_x', 'A_y', 'A_z']\n",
    "\n",
    "    M = getActivityLevelmap()\n",
    "    \n",
    "    subDirs = os.listdir(dirName)\n",
    "    \n",
    "    all_features = []\n",
    "    actual_label = []\n",
    "    activity_level = []\n",
    "    cnt = 0\n",
    "    for subDir in subDirs:\n",
    "#         if cnt>10:\n",
    "#             break\n",
    "        print(subDir)\n",
    "        pidsids = os.listdir(dirName + subDir )\n",
    "        for pidsid in pidsids:\n",
    "#             if cnt>10:\n",
    "#                 break\n",
    "            cnt=cnt+1\n",
    "            D = pd.read_csv(dirName + subDir + '/' + pidsid + '/' + filename, names = column_names)\n",
    "            x= D['A_x']\n",
    "            y= D['A_y']\n",
    "            z= D['A_z']\n",
    "            ts= D['timestamp']\n",
    "            features = computeWindowFeatures(ts, x, y, z, window_size=10*1000)\n",
    "\n",
    "            for f in features:\n",
    "                all_features.append(f)\n",
    "                actual_label.append([subDir])\n",
    "                activity_level.append([M[subDir]])\n",
    "    \n",
    "    print(len(all_features))\n",
    "    print(len(actual_label))\n",
    "    print(len(activity_level))\n",
    "    a = np.array(all_features)\n",
    "    b = np.array(actual_label)\n",
    "    c = np.array(activity_level)\n",
    "#     print(a)\n",
    "#     print(b)\n",
    "#     print(c)\n",
    "    \n",
    "    D = np.concatenate( (a, b, c), axis=1)\n",
    "#     print(D)\n",
    "\n",
    "#     foo = np.array([1,2,3])\n",
    "#     with open(dirName + 'featureFile.csv', 'wb') as f:\n",
    "#         np.savetxt(f, D, delimiter=\",\")\n",
    "    np.savetxt(dirName + 'featureFile.csv', D, delimiter=',', fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BICYCLING', 'CLEANING', 'COMPUTER WORK', 'COOKING', 'DOING LAUNDRY', 'EATING', 'exercise', 'LAB WORK', 'LYING DOWN']\n"
     ]
    }
   ],
   "source": [
    "dirName = 'C:/Research/Data/Activity/streamprocessor-like-data-25hz/'\n",
    "print(os.listdir(dirName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [2, 3, 4], [4, 5, 6]]\n",
      "[['a'], ['b'], ['c']]\n",
      "[['1' '2' '3' 'a' 'aa']\n",
      " ['2' '3' '4' 'b' 'ab']\n",
      " ['4' '5' '6' 'c' 'ac']]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "\n",
    "A=[[1, 2, 3],\n",
    "   [2,3, 4],\n",
    "   [4, 5, 6]]\n",
    "B = [['a'], ['b'], ['c']]\n",
    "C = [['aa'], ['ab'], ['ac']]\n",
    "\n",
    "print(A)\n",
    "print(B)\n",
    "a = np.array(A)\n",
    "b = np.array(B)\n",
    "c = np.array(C)\n",
    "print(np.concatenate( (a, b, c), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [1, 2, 3]]\n"
     ]
    }
   ],
   "source": [
    "A = []\n",
    "A.append([1, 2, 3])\n",
    "A.append([1, 2, 3])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
