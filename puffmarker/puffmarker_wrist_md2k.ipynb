{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6292176e-0ac3-11e8-9b8d-a434d9b1e6b7 - 636fcc1f-8966-4e63-a9df-0cbaa6e9296c - [DataPoint(2017-10-07 13:59:56.441000, 2017-10-07 14:59:55.598000, 86535]\n",
      "[DataPoint(2017-10-07 13:59:56.441000, 2017-10-07 14:59:55.598000, 86535]\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) 2017, MD2K Center of Excellence\n",
    "# - Nasir Ali <nasir.ali08@gmail.com>\n",
    "# - Timothy Hnat <twhnat@memphis.edu>\n",
    "# All rights reserved.\n",
    "#\n",
    "# Redistribution and use in source and binary forms, with or without\n",
    "# modification, are permitted provided that the following conditions are met:\n",
    "#\n",
    "# * Redistributions of source code must retain the above copyright notice, this\n",
    "# list of conditions and the following disclaimer.\n",
    "#\n",
    "# * Redistributions in binary form must reproduce the above copyright notice,\n",
    "# this list of conditions and the following disclaimer in the documentation\n",
    "# and/or other materials provided with the distribution.\n",
    "#\n",
    "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
    "# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
    "# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
    "# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
    "# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
    "# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
    "# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
    "# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
    "# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    "\n",
    "import datetime\n",
    "import uuid\n",
    "from typing import List\n",
    "from uuid import UUID\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# from cerebralcortex.core.datatypes.datapoint import DataPoint\n",
    "# from cerebralcortex.core.datatypes.datastream import DataStream\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from typing import Any\n",
    "import sys\n",
    "import json\n",
    "import codecs\n",
    "import gzip\n",
    "\n",
    "class DataPoint:\n",
    "    def __init__(self,\n",
    "                 start_time: datetime = None,\n",
    "                 end_time: datetime = None,\n",
    "                 sample: Any = None):\n",
    "        self._start_time = start_time\n",
    "        self._end_time = end_time\n",
    "        self._sample = sample\n",
    "\n",
    "    @property\n",
    "    def sample(self):\n",
    "        return self._sample\n",
    "\n",
    "    @sample.setter\n",
    "    def sample(self, val):\n",
    "        self._sample = val\n",
    "\n",
    "    @property\n",
    "    def start_time(self):\n",
    "        return self._start_time\n",
    "\n",
    "    @start_time.setter\n",
    "    def start_time(self, val):\n",
    "        self._start_time = val\n",
    "\n",
    "    @property\n",
    "    def end_time(self):\n",
    "        return self._end_time\n",
    "\n",
    "    @end_time.setter\n",
    "    def end_time(self, val):\n",
    "        self._end_time = val\n",
    "\n",
    "    @classmethod\n",
    "    def from_tuple(cls, start_time: datetime, sample: Any, end_time: datetime = None):\n",
    "        return cls(start_time, end_time, sample)\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.start_time) + \" - \" + str(self.sample)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'DataPoint(' + ', '.join(map(str, [self.start_time, self.end_time, self.sample]))\n",
    "\n",
    "\n",
    "class DataStream:\n",
    "    def __init__(self,\n",
    "                 identifier: UUID = None,\n",
    "                 owner: UUID = None,\n",
    "                 name: UUID = None,\n",
    "                 data_descriptor = [],\n",
    "                 execution_context = {},\n",
    "                 annotations: List = [],\n",
    "                 stream_type: str = \"1\",\n",
    "                 start_time: datetime = None,\n",
    "                 end_time: datetime = None,\n",
    "                 data: List[DataPoint] = None\n",
    "                 ):\n",
    "        self._identifier = identifier\n",
    "        self._owner = owner\n",
    "        self._name = name\n",
    "        self._data_descriptor = data_descriptor\n",
    "        self._datastream_type = stream_type\n",
    "        self._execution_context = execution_context\n",
    "        self._annotations = annotations\n",
    "        self._start_time = start_time\n",
    "        self._end_time = end_time\n",
    "        self._data = data\n",
    "\n",
    "\n",
    "    @property\n",
    "    def identifier(self):\n",
    "        return self._identifier\n",
    "\n",
    "    @property\n",
    "    def owner(self):\n",
    "        return self._owner\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "\n",
    "    @name.setter\n",
    "    def name(self, value):\n",
    "        self._name = value\n",
    "\n",
    "    @property\n",
    "    def start_time(self):\n",
    "        return self._start_time\n",
    "\n",
    "    @start_time.setter\n",
    "    def start_time(self, val):\n",
    "        self._start_time = val\n",
    "\n",
    "    @property\n",
    "    def end_time(self):\n",
    "        return self._end_time\n",
    "\n",
    "    @end_time.setter\n",
    "    def end_time(self, val):\n",
    "        self._end_time = val\n",
    "\n",
    "    @property\n",
    "    def datastream_type(self):\n",
    "        return self._datastream_type\n",
    "\n",
    "    @property\n",
    "    def data(self):\n",
    "        return self._data\n",
    "\n",
    "    \n",
    "    @data.setter\n",
    "    def data(self, value):\n",
    "        result = []\n",
    "        for dp in value:\n",
    "            result.append(DataPoint(dp.start_time, dp.end_time, dp.sample))\n",
    "        self._data = result\n",
    "\n",
    "    @classmethod\n",
    "    def from_datastream(cls, input_streams: List):\n",
    "        result = cls(owner=input_streams[0].owner)\n",
    "        # TODO: Something with provenance tracking from datastream list\n",
    "        return result\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.identifier) + \" - \" + str(self.owner) + \" - \" + str(self.data)\n",
    "\n",
    "    def __repr__(self):\n",
    "        result = \"Stream(\" + ', '.join(map(str, [self.identifier,\n",
    "                                                 self.owner,\n",
    "                                                 self.name,\n",
    "                                                 self.data_descriptor,\n",
    "                                                 self.datastream_type,\n",
    "                                                 self.execution_context,\n",
    "                                                 self.annotations]))\n",
    "        return result\n",
    "\n",
    "def convert_sample(sample):\n",
    "    return list([float(x.strip()) for x in sample.split(',')])\n",
    "\n",
    "\n",
    "def line_parser(input):\n",
    "    ts, offset, sample = input.split(',', 2)\n",
    "    start_time = int(ts) / 1000.0\n",
    "    offset = int(offset)\n",
    "    return DataPoint(datetime.fromtimestamp(start_time), convert_sample(sample))\n",
    "\n",
    "\n",
    "def load_datastream(filebase):\n",
    "    metadata = {}\n",
    "    with codecs.open(filebase + '.json', encoding='utf-8', errors='ignore') as f:\n",
    "        metadata = json.loads(f.read())\n",
    "\n",
    "    fp = gzip.open(filebase + '.gz')\n",
    "    gzip_file_content = fp.read()\n",
    "    fp.close()\n",
    "    gzip_file_content = gzip_file_content.decode('utf-8')\n",
    "\n",
    "    lines = gzip_file_content.splitlines()\n",
    "    data = list(map(line_parser, lines))\n",
    "\n",
    "    identifier = uuid.UUID(metadata['identifier'])\n",
    "    owner = uuid.UUID(metadata['owner'])\n",
    "    name = metadata['name']\n",
    "    data_descriptor = metadata['data_descriptor']\n",
    "    execution_context = metadata['execution_context']\n",
    "    annotations = metadata['annotations']\n",
    "    stream_type = \"1\"\n",
    "    start_time = data[0].start_time\n",
    "    end_time = data[-1].start_time\n",
    "\n",
    "    return DataStream(identifier,owner,name,\n",
    "    data_descriptor,\n",
    "    execution_context,\n",
    "    annotations,\n",
    "    stream_type,\n",
    "    start_time,\n",
    "    end_time,\n",
    "    data)\n",
    "\n",
    "\n",
    "def save_datastream(datastream):\n",
    "    print(datastream)\n",
    "    print(datastream.data)\n",
    "    pass\n",
    "\n",
    "\n",
    "def count(datastream):\n",
    "\n",
    "    identifier = uuid.uuid1()\n",
    "    name = datastream.name + '--COUNT'\n",
    "    execution_context = {}\n",
    "    annotations = {}\n",
    "    data_descriptor = []\n",
    "\n",
    "\n",
    "    data = [DataPoint(datastream.data[0].start_time, datastream.data[-1].start_time, len(datastream.data))]\n",
    "    start_time = data[0].start_time\n",
    "    end_time = data[-1].start_time\n",
    "\n",
    "    return DataStream(identifier, datastream.owner, name, data_descriptor,\n",
    "    execution_context,\n",
    "    annotations,\n",
    "    \"1\",\n",
    "    start_time,\n",
    "    end_time,\n",
    "    data)\n",
    "\n",
    "\n",
    "def magnitude(datastream: DataStream) -> DataStream:\n",
    "    \"\"\"\n",
    "\n",
    "    :param datastream:\n",
    "    :return: magnitude of the dataastream\n",
    "    \"\"\"\n",
    "    result = DataStream.from_datastream(input_streams=[datastream])\n",
    "    if datastream.data is None or len(datastream.data) == 0:\n",
    "        result.data = []\n",
    "        return result\n",
    "\n",
    "    input_data = np.array([i.sample for i in datastream.data])\n",
    "\n",
    "    data = norm(input_data, axis=1).tolist()\n",
    "\n",
    "    result.data = [DataPoint.from_tuple(start_time=v.start_time, sample=data[i])\n",
    "                   for i, v in enumerate(datastream.data)]\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def smooth(datastream: DataStream,\n",
    "           span: int = 5) -> DataStream:\n",
    "    \n",
    "    data = datastream.data\n",
    "    \"\"\"\n",
    "    Smooths data using moving average filter over a span.\n",
    "    The first few elements of data_smooth are given by\n",
    "    data_smooth(1) = data(1)\n",
    "    data_smooth(2) = (data(1) + data(2) + data(3))/3\n",
    "    data_smooth(3) = (data(1) + data(2) + data(3) + data(4) + data(5))/5\n",
    "    data_smooth(4) = (data(2) + data(3) + data(4) + data(5) + data(6))/5\n",
    "\n",
    "    for more details follow the below links:\n",
    "    https://www.mathworks.com/help/curvefit/smooth.html\n",
    "    http://stackoverflow.com/a/40443565\n",
    "\n",
    "    :return: data_smooth\n",
    "    :param data:\n",
    "    :param span:\n",
    "    \"\"\"\n",
    "\n",
    "    if data is None or len(data) == 0:\n",
    "        return []\n",
    "\n",
    "    sample = [i.sample for i in data]\n",
    "    sample_middle = np.convolve(sample, np.ones(span, dtype=int), 'valid') / span\n",
    "    divisor = np.arange(1, span - 1, 2)\n",
    "    sample_start = np.cumsum(sample[:span - 1])[::2] / divisor\n",
    "    sample_end = (np.cumsum(sample[:-span:-1])[::2] / divisor)[::-1]\n",
    "    sample_smooth = np.concatenate((sample_start, sample_middle, sample_end))\n",
    "\n",
    "    data_smooth = []\n",
    "\n",
    "    if len(sample_smooth) == len(data):\n",
    "        for i, item in enumerate(data):\n",
    "            dp = DataPoint.from_tuple(sample=sample_smooth[i], start_time=item.start_time, end_time=item.end_time)\n",
    "            data_smooth.append(dp)\n",
    "    else:\n",
    "        raise Exception(\"Smoothed data length does not match with original data length.\")\n",
    "\n",
    "    data_smooth_stream = DataStream.from_datastream([datastream])\n",
    "    data_smooth_stream.data = data_smooth\n",
    "    return data_smooth_stream\n",
    "\n",
    "\n",
    "def moving_average_curve(data: List[DataPoint],\n",
    "                         window_length: int) -> List[DataPoint]:\n",
    "    \"\"\"\n",
    "    Moving average curve from filtered (using moving average) samples.\n",
    "\n",
    "    :return: mac\n",
    "    :param data:\n",
    "    :param window_length:\n",
    "    \"\"\"\n",
    "    if data is None or len(data) == 0:\n",
    "        return []\n",
    "\n",
    "    sample = [i.sample for i in data]\n",
    "    mac = []\n",
    "    for i in range(window_length, len(sample) - (window_length + 1)):\n",
    "        sample_avg = np.mean(sample[i - window_length:i + window_length + 1])\n",
    "        mac.append(DataPoint.from_tuple(sample=sample_avg, start_time=data[i].start_time, end_time=data[i].end_time))\n",
    "\n",
    "    return mac\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    filename = '7007221c-1aec-4481-aee2-200c7e61533d'\n",
    "\n",
    "#     datastream = load_datastream(sys.argv[1])\n",
    "    datastream = load_datastream(filename)\n",
    "    number_entries = count(datastream)\n",
    "    save_datastream(number_entries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nsaleheen/data/csvdataSI_new/p05/s01/\n",
      "success\n",
      "10509\n",
      "10509\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'getMag' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ae7a4fcc0819>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mnSample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnSample\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpuff_times\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m                 \u001b[0mA_mag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetMag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m                 \u001b[0mgyr_mag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetMag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'getMag' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import math\n",
    "import statistics\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "def segmentationUsingTwoMovingAverage(slowMovingAverageDataStream: DataStream\n",
    "                                      , fastMovingAverageDataStream: DataStream\n",
    "                                      , THRESHOLD: float, near: int):\n",
    "    \n",
    "    slowMovingAverage = np.array([data.sample for data in slowMovingAverageDataStream.data])\n",
    "    fastMovingAverage = np.array([data.sample for data in fastMovingAverageDataStream.data])\n",
    "\n",
    "    indexList = [0]*len(slowMovingAverage)\n",
    "    curIndex = 0;\n",
    "\n",
    "    for i in range(len(slowMovingAverage)):\n",
    "        diff = slowMovingAverage[i] - fastMovingAverage[i]\n",
    "        if diff > THRESHOLD:\n",
    "            if curIndex == 0:\n",
    "                indexList[curIndex] = i\n",
    "                curIndex = curIndex + 1\n",
    "                indexList[curIndex] = i\n",
    "            else:\n",
    "                if i <= indexList[curIndex] + near :\n",
    "                    indexList[curIndex] = i\n",
    "                else:\n",
    "                    curIndex = curIndex + 1\n",
    "                    indexList[curIndex] = i\n",
    "                    curIndex = curIndex + 1\n",
    "                    indexList[curIndex] = i\n",
    "\n",
    "    output = []\n",
    "    if curIndex > 0:\n",
    "        for i in range(0, curIndex, 2):\n",
    "            sIndex = indexList[i]\n",
    "            eIndex = indexList[i+1]\n",
    "            sTime = slowMovingAverageDataStream.data[sIndex].start_time\n",
    "            eTime = slowMovingAverageDataStream.data[eIndex].start_time\n",
    "            output.append(DataPoint(start_time=sTime, end_time=eTime, sample=[indexList[i], indexList[i + 1]]))\n",
    "\n",
    "    intersectionPoints = DataStream.from_datastream([slowMovingAverageDataStream])\n",
    "    intersectionPoints.data = output\n",
    "    return intersectionPoints\n",
    "\n",
    "    return intersectionPoints\n",
    "\n",
    "def calculateRollStream(accel_stream: DataStream) :\n",
    "    roll = []\n",
    "    for dp in accel_stream.data:\n",
    "        ax = dp.sample[0]\n",
    "        ay = dp.sample[1]\n",
    "        az = dp.sample[2]\n",
    "        rll = 180 * math.atan2(ax, math.sqrt(ay * ay + az * az)) / math.pi\n",
    "        roll.append(DataPoint.from_tuple(start_time=dp.start_time, end_time=dp.end_time, sample=rll))\n",
    "\n",
    "    roll_datastream = DataStream.from_datastream([accel_stream])\n",
    "    roll_datastream.data = roll\n",
    "    return roll_datastream\n",
    "\n",
    "def calculatePitchStream(accel_stream: DataStream):\n",
    "    pitch = []\n",
    "    for dp in accel_stream.data:\n",
    "        ax = dp.sample[0]\n",
    "        ay = dp.sample[1]\n",
    "        az = dp.sample[2]\n",
    "        ptch = 180 * math.atan2(-ay, -az) / math.pi\n",
    "        pitch.append(DataPoint.from_tuple(start_time=dp.start_time, end_time=dp.end_time, sample=ptch))\n",
    "\n",
    "    pitch_datastream = DataStream.from_datastream([accel_stream])\n",
    "    pitch_datastream.data = pitch\n",
    "    return pitch_datastream\n",
    "\n",
    "def calculateYawStream(accel_stream: DataStream):\n",
    "    yaw = []\n",
    "    for dp in accel_stream.data:\n",
    "        ax = dp.sample[0]\n",
    "        ay = dp.sample[1]\n",
    "        az = dp.sample[2]\n",
    "        yw = 180 * math.atan2(ay, ax) / math.pi\n",
    "        yaw.append(DataPoint.from_tuple(start_time=dp.start_time, end_time=dp.end_time, sample=yw))\n",
    "\n",
    "    yaw_datastream = DataStream.from_datastream([accel_stream])\n",
    "    yaw_datastream.data = yaw\n",
    "    return yaw_datastream\n",
    "\n",
    "\n",
    "def filterDuration(gyr_intersections: DataStream):\n",
    "    gyr_intersections_filtered = []\n",
    "    \n",
    "    for I in gyr_intersections.data:\n",
    "        dur = (I.end_time - I.start_time).total_seconds()\n",
    "#         print(dur)\n",
    "        if (dur >= 1.0) & (dur <= 5.0):\n",
    "            gyr_intersections_filtered.append(I)\n",
    "\n",
    "    gyr_intersections_filtered_datastream = DataStream.from_datastream([gyr_intersections])\n",
    "    gyr_intersections_filtered_datastream.data = gyr_intersections_filtered\n",
    "    return gyr_intersections_filtered_datastream\n",
    "\n",
    "def filterRollPitch(gyr_intersections_stream: DataStream, roll_stream: DataStream, pitch_stream: DataStream):\n",
    "    gyr_intersections_filtered = []\n",
    "    \n",
    "    for I in gyr_intersections_stream.data:\n",
    "        sTime = I.start_time\n",
    "        eTime = I.end_time\n",
    "        sIndex = I.sample[0]\n",
    "        eIndex = I.sample[1]\n",
    "        \n",
    "        roll_sub = [roll_stream.data[i].sample for i in range(sIndex, eIndex)]\n",
    "        pitch_sub = [pitch_stream.data[i].sample for i in range(sIndex, eIndex)]\n",
    "        \n",
    "        mean_roll = np.mean(roll_sub)\n",
    "        mean_pitch = np.mean(pitch_sub)\n",
    "        \n",
    "#         r > -20 && r <= 65 && p >= -125 && p <= -40\n",
    "        if (mean_roll > -20) & (mean_roll <= 65) & (mean_pitch >= - 125) & (mean_pitch <= - 40):\n",
    "            gyr_intersections_filtered.append(I)\n",
    "\n",
    "    gyr_intersections_filtered_stream = DataStream.from_datastream([gyr_intersections_stream])\n",
    "    gyr_intersections_filtered_stream.data = gyr_intersections_filtered\n",
    "    return gyr_intersections_filtered_stream\n",
    "\n",
    "def computeBasicFeatures(data):\n",
    "    \n",
    "    mean = np.mean(data)\n",
    "    median = np.median(data)\n",
    "    sd = np.std(data)\n",
    "    quartile = np.percentile(data, 75) - np.percentile(data, 25)\n",
    "    \n",
    "    return mean, median, sd, quartile\n",
    "\n",
    "def computeWindowFeatures(gyr_intersections_stream, gyr_mag_stream, roll_stream, pitch_stream, yaw_stream, accel_stream):\n",
    "\n",
    "    all_features = []\n",
    "    \n",
    "    for I in gyr_intersections_stream.data:\n",
    "        sTime = I.start_time\n",
    "        eTime = I.end_time\n",
    "        sIndex = I.sample[0]\n",
    "        eIndex = I.sample[1]\n",
    "        \n",
    "        roll_sub = [roll_stream.data[i].sample for i in range(sIndex, eIndex)]\n",
    "        pitch_sub = [pitch_stream.data[i].sample for i in range(sIndex, eIndex)]\n",
    "        yaw_sub = [yaw_stream.data[i].sample for i in range(sIndex, eIndex)]\n",
    "\n",
    "        Gmag_sub = [gyr_mag_stream.data[i].sample for i in range(sIndex, eIndex)]\n",
    "    \n",
    "        duration = 1000 * (eTime - sTime).total_seconds()\n",
    "        \n",
    "        roll_mean, roll_median, roll_sd, roll_quartile = computeBasicFeatures(roll_sub)\n",
    "        pitch_mean, pitch_median, pitch_sd, pitch_quartile = computeBasicFeatures(pitch_sub)\n",
    "        yaw_mean, yaw_median, yaw_sd, yaw_quartile = computeBasicFeatures(yaw_sub)\n",
    "        \n",
    "        gyro_mean, gyro_median, gyro_sd, gyro_quartile = computeBasicFeatures(Gmag_sub)\n",
    "        \n",
    "        f = [duration, roll_mean, roll_median, roll_sd, roll_quartile, pitch_mean, pitch_median, pitch_sd, pitch_quartile, yaw_mean, yaw_median, yaw_sd, yaw_quartile, gyro_mean, gyro_median, gyro_sd, gyro_quartile]\n",
    "        \n",
    "        all_features.append(DataPoint.from_tuple(start_time=sTime, sample=f))\n",
    "        \n",
    "    feature_vector_stream = DataStream.from_datastream([all_features])\n",
    "    feature_vector_stream.data = all_features\n",
    "    return feature_vector_stream\n",
    "\n",
    "def getLabel(st, et, epi_st, epi_et, puff_times):\n",
    "    label = 0 # not puff\n",
    "#     print(range(len(puff_times)))\n",
    "    for i in range(len(puff_times)):\n",
    "        if (puff_times[i] >= st) & (puff_times[i] <= et):\n",
    "            label = 1\n",
    "            return label\n",
    "    \n",
    "    for i in range(len(epi_et)):\n",
    "        if ((epi_st[i] <=st) & (st <= epi_et[i])) | ((epi_st[i] <=et) & (et <= epi_et[i])):\n",
    "            label = -1 # included episode but not puff\n",
    "            return label\n",
    "    return label\n",
    "\n",
    "def getData(cur_dir, filename):\n",
    "    col_name = ['timestamp', 'value']\n",
    "    D = pd.read_csv(cur_dir + filename, names = col_name)\n",
    "    \n",
    "    return D['timestamp'], D['value']\n",
    "\n",
    "def convert_sample(sample):\n",
    "    return list([float(x.strip()) for x in sample.split(',')])\n",
    "\n",
    "\n",
    "def line_parser(input):\n",
    "    ts, offset, sample = input.split(',', 2)\n",
    "    start_time = int(ts) / 1000.0\n",
    "    offset = int(offset)\n",
    "    return DataPoint(datetime.fromtimestamp(start_time), convert_sample(sample))\n",
    "\n",
    "def getInputData(cur_dir, wrist):\n",
    "    \n",
    "    epi_st, epi_et = getData(cur_dir, 'episode_start_end.csv')\n",
    "    \n",
    "    if wrist == 0:\n",
    "        puff_times = pd.read_csv(cur_dir + 'puff_timestamp_leftwrist.csv', names=['timings'])\n",
    "        puff_times = puff_times['timings']\n",
    "        puff_times = puff_times.values\n",
    "\n",
    "        t, Ax = getData(cur_dir, 'left-wrist-accelx.csv')\n",
    "        t, Ay = getData(cur_dir, 'left-wrist-accely.csv')\n",
    "        t, Az = getData(cur_dir, 'left-wrist-accelz.csv')\n",
    "\n",
    "        t, Gx = getData(cur_dir, 'left-wrist-gyrox.csv')\n",
    "        t, Gy = getData(cur_dir, 'left-wrist-gyroy.csv')\n",
    "        t, Gz = getData(cur_dir, 'left-wrist-gyroz.csv')\n",
    "    else:\n",
    "        puff_times = pd.read_csv(cur_dir + 'puff_timestamp_rightwrist.csv', names=['timings'])\n",
    "        puff_times = puff_times['timings']\n",
    "        puff_times = puff_times.values\n",
    "\n",
    "        t, Ax = getData(cur_dir, 'right-wrist-accelx.csv')\n",
    "        t, Ay = getData(cur_dir, 'right-wrist-accely.csv')\n",
    "        t, Az = getData(cur_dir, 'right-wrist-accelz.csv')\n",
    "\n",
    "        t, Gx = getData(cur_dir, 'right-wrist-gyrox.csv')\n",
    "        t, Gy = getData(cur_dir, 'right-wrist-gyroy.csv')\n",
    "        t, Gz = getData(cur_dir, 'right-wrist-gyroz.csv')\n",
    "    \n",
    "    return t, Ax, Ay, Az, Gx, Gy, Gz, epi_st, epi_et, puff_times\n",
    "\n",
    "def getInputDataStream(cur_dir, wrist):\n",
    "    \n",
    "    t, Ax, Ay, Az, Gx, Gy, Gz, epi_st, epi_et, puff_times = getInputData(cur_dir, wrist)\n",
    "    accel_data = []\n",
    "    gyro_data = []\n",
    "    for i in range(len(t)):\n",
    "        accel_data.append(DataPoint.from_tuple(start_time=datetime.fromtimestamp(t.iloc[i]/1000), sample = [Ax.iloc[i], Ay.iloc[i], Az.iloc[i]]))\n",
    "        gyro_data.append(DataPoint.from_tuple(start_time=datetime.fromtimestamp(t.iloc[i]/1000), sample = [Gx.iloc[i], Gy.iloc[i], Gz.iloc[i]]))\n",
    "            \n",
    "    start_time = accel_data[0].start_time\n",
    "    end_time = accel_data[-1].start_time\n",
    "    \n",
    "    identifier = 'joy001'\n",
    "    name = datastream.name + '--COUNT'\n",
    "    execution_context = {}\n",
    "    annotations = {}\n",
    "    data_descriptor = []\n",
    "\n",
    "    accel_datastream = DataStream(identifier, 'owner', 'accel', data_descriptor,\n",
    "        execution_context,\n",
    "        annotations,\n",
    "        \"1\",\n",
    "        start_time,\n",
    "        end_time,\n",
    "        accel_data)\n",
    "    gyro_datastream = DataStream(identifier, 'owner', 'gyro', data_descriptor,\n",
    "        execution_context,\n",
    "        annotations,\n",
    "        \"1\",\n",
    "        start_time,\n",
    "        end_time,\n",
    "        accel_data)\n",
    "    \n",
    "    return accel_datastream, gyro_datastream # t, Ax, Ay, Az, Gx, Gy, Gz, epi_st, epi_et, puff_times\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "#     cur_dir = 'C:\\\\Users\\\\sakther\\\\Documents\\\\python_workshop\\\\md2k_mCerebralCortex\\\\wristdata\\\\'\n",
    "#     cur_dir = 'C:\\\\Users\\\\sakther\\\\DATA\\\\csvdataSI_new\\\\p03\\\\s03\\\\'\n",
    "\n",
    "    fastSize = 13\n",
    "    slowSize = 131\n",
    "    \n",
    "    data_dir = '/home/nsaleheen/data/csvdataSI_new/'\n",
    "\n",
    "#     pids = ['p01', 'p02', 'p03', 'p04', 'p05', 'p06']\n",
    "    pids = ['p05']\n",
    "    Xs = []\n",
    "    Ys = []\n",
    "    nSample = 0\n",
    "\n",
    "    for i in range(len(pids)):\n",
    "        basedir = data_dir + pids[i] + '/'\n",
    "        sids = [d for d in os.listdir(basedir) if os.path.isdir(os.path.join(basedir, d))]     \n",
    "\n",
    "        for j in range(len(sids)):\n",
    "            cur_dir = data_dir + pids[i] + '/' + sids[j] + '/'\n",
    "            print(cur_dir)\n",
    "            \n",
    "            for wrist in range(2): # 0 for left wrist, 1 for right wrist\n",
    "            \n",
    "                t, Ax, Ay, Az, Gx, Gy, Gz, epi_st, epi_et, puff_times = getInputData(cur_dir, wrist)\n",
    "                accel_stream, gyro_stream = getInputDataStream(cur_dir, wrist)\n",
    "                print('success')\n",
    "                print(len(accel_stream.data))\n",
    "                print(len(Ax))\n",
    "\n",
    "                nSample = nSample + len(puff_times)\n",
    "\n",
    "                A_mag = getMag(Ax, Ay, Az)\n",
    "                gyr_mag = getMag(Gx, Gy, Gz)\n",
    "\n",
    "                roll = calculateRoll(Ax, Ay, Az)\n",
    "                pitch = calculatePitch(Ax, Ay, Az)\n",
    "                yaw = calculateYaw(Ax, Ay, Az)\n",
    "\n",
    "                roll_datastream = calculateRollStream(accel_stream)\n",
    "                pitch_datastream = calculatePitchStream(accel_stream)\n",
    "                yaw_datastream = calculateYawStream(accel_stream)\n",
    "\n",
    "                gyr_mag_800 = smooth(gyr_mag, fastSize)\n",
    "                gyr_mag_8000 = smooth(gyr_mag, slowSize)\n",
    "                gyr_intersections, dont_care = segmentationUsingTwoMovingAverage(gyr_mag_8000, gyr_mag_800, 0, 4)\n",
    "                gyr_intersections = filterDuration(gyr_intersections, t)\n",
    "                gyr_intersections = filterRollPitch(gyr_intersections, roll, pitch)\n",
    "\n",
    "                all_features = computeWindowFeatures(gyr_intersections, gyr_mag, roll, pitch, yaw, Ax, Ay, Az, t)\n",
    "\n",
    "                st = [f[0] for f in all_features]\n",
    "                et = [f[0]+f[1] for f in all_features]\n",
    "                labels = [0]*len(st)\n",
    "\n",
    "                for k in range(len(st)):\n",
    "                    labels[k] = getLabel(st[k], et[k], epi_st, epi_et, puff_times)\n",
    "                    if labels[k] != -1:\n",
    "                        Xs.append(all_features[k][1:])\n",
    "                        if labels[k] == 0:\n",
    "                            Ys.append('non-puff')\n",
    "                        else:\n",
    "                            Ys.append('puff')\n",
    "\n",
    "                print(len(Xs))\n",
    "    #             print(sum(Ys))     \n",
    "        \n",
    "    print(len(Ys))\n",
    "#     print(sum(Ys))\n",
    "    print(nSample)\n",
    "    \n",
    "#     print(Xs)\n",
    "#     print(Ys)\n",
    "\n",
    "    Xs = np.array(Xs)\n",
    "    Ys = np.array([Ys])\n",
    "    M = np.concatenate((Xs, Ys.T), axis=1)\n",
    "\n",
    "    df = pd.DataFrame(M)\n",
    "    feature_name = ['duration', 'roll_mean', 'roll_median', 'roll_sd', 'roll_quartile', 'pitch_mean', 'pitch_median', 'pitch_sd', 'pitch_quartile', 'yaw_mean', 'yaw_median', 'yaw_sd', 'yaw_quartile', 'gyro_mean', 'gyro_median', 'gyro_sd', 'gyro_quartile', 'label(1:puff; 0:non-puff)']\n",
    "    df.to_csv(\"feature_file_puffmarker_wrist_py.csv\", header=feature_name)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nsaleheen/data/csvdataSI_new/p05/s01/\n",
      "success\n",
      "10509\n",
      "10509\n",
      "gyr_intersections\n",
      "2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'DataStream' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-30eb23f85e6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0mdoProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccel_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgyro_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mnSample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnSample\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpuff_times\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-30eb23f85e6a>\u001b[0m in \u001b[0;36mdoProcess\u001b[0;34m(accel_stream, gyro_stream)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgyr_intersections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mall_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputeWindowFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgyr_intersections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgyr_mag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpitch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myaw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-f15fb98d2c99>\u001b[0m in \u001b[0;36mcomputeWindowFeatures\u001b[0;34m(gyr_intersections, gyr_mag, roll, pitch, yaw, Ax, Ay, Az, t)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcomputeWindowFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgyr_intersections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgyr_mag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpitch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myaw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mall_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mI\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgyr_intersections\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0mroll_sub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mroll\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mpitch_sub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpitch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpitch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataStream' object is not iterable"
     ]
    }
   ],
   "source": [
    "def doProcess(accel_stream, gyro_stream):\n",
    "\n",
    "    A_mag_stream = magnitude(accel_stream)\n",
    "    gyr_mag_stream = magnitude(gyro_stream)\n",
    "\n",
    "    roll_datastream = calculateRollStream(accel_stream)\n",
    "    pitch_datastream = calculatePitchStream(accel_stream)\n",
    "    yaw_datastream = calculateYawStream(accel_stream)\n",
    "\n",
    "    gyr_mag_800 = smooth(gyr_mag_stream, fastSize)\n",
    "    gyr_mag_8000 = smooth(gyr_mag_stream, slowSize)\n",
    "    \n",
    "    gyr_intersections = segmentationUsingTwoMovingAverage(gyr_mag_8000, gyr_mag_800, 0, 4)\n",
    "    \n",
    "    gyr_intersections = filterDuration(gyr_intersections)\n",
    "    gyr_intersections = filterRollPitch(gyr_intersections, roll_datastream, pitch_datastream)\n",
    "    \n",
    "    print('gyr_intersections')\n",
    "    print(len(gyr_intersections.data))\n",
    "\n",
    "    all_features = computeWindowFeatures(gyr_intersections, gyr_mag_stream, roll_datastream, pitch_datastream, yaw_datastream, accel_stream)\n",
    "\n",
    "    st = [f[0] for f in all_features]\n",
    "    et = [f[0]+f[1] for f in all_features]\n",
    "    labels = [0]*len(st)\n",
    "\n",
    "    for k in range(len(st)):\n",
    "        labels[k] = getLabel(st[k], et[k], epi_st, epi_et, puff_times)\n",
    "        if labels[k] != -1:\n",
    "            Xs.append(all_features[k][1:])\n",
    "            if labels[k] == 0:\n",
    "                Ys.append('non-puff')\n",
    "            else:\n",
    "                Ys.append('puff')\n",
    "\n",
    "    print(len(Xs))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "#     cur_dir = 'C:\\\\Users\\\\sakther\\\\Documents\\\\python_workshop\\\\md2k_mCerebralCortex\\\\wristdata\\\\'\n",
    "#     cur_dir = 'C:\\\\Users\\\\sakther\\\\DATA\\\\csvdataSI_new\\\\p03\\\\s03\\\\'\n",
    "\n",
    "    fastSize = 13\n",
    "    slowSize = 131\n",
    "    \n",
    "    data_dir = '/home/nsaleheen/data/csvdataSI_new/'\n",
    "\n",
    "    pids = ['p01', 'p02', 'p03', 'p04', 'p05', 'p06']\n",
    "    pids = ['p05']\n",
    "    Xs = []\n",
    "    Ys = []\n",
    "    nSample = 0\n",
    "\n",
    "    for i in range(len(pids)):\n",
    "        basedir = data_dir + pids[i] + '/'\n",
    "        sids = [d for d in os.listdir(basedir) if os.path.isdir(os.path.join(basedir, d))]     \n",
    "\n",
    "        for j in range(len(sids)):\n",
    "            cur_dir = data_dir + pids[i] + '/' + sids[j] + '/'\n",
    "            print(cur_dir)\n",
    "            \n",
    "            for wrist in range(2): # 0 for left wrist, 1 for right wrist\n",
    "            \n",
    "                t, Ax, Ay, Az, Gx, Gy, Gz, epi_st, epi_et, puff_times = getInputData(cur_dir, wrist)\n",
    "                accel_stream, gyro_stream = getInputDataStream(cur_dir, wrist)\n",
    "                print('success')\n",
    "                print(len(accel_stream.data))\n",
    "                print(len(Ax))\n",
    "                \n",
    "                doProcess(accel_stream, gyro_stream)\n",
    "\n",
    "                nSample = nSample + len(puff_times)\n",
    "\n",
    "                A_mag = getMag(Ax, Ay, Az)\n",
    "                gyr_mag = getMag(Gx, Gy, Gz)\n",
    "\n",
    "                roll = calculateRoll(Ax, Ay, Az)\n",
    "                pitch = calculatePitch(Ax, Ay, Az)\n",
    "                yaw = calculateYaw(Ax, Ay, Az)\n",
    "\n",
    "                roll_datastream = calculateRollStream(accel_stream)\n",
    "                pitch_datastream = calculatePitchStream(accel_stream)\n",
    "                yaw_datastream = calculateYawStream(accel_stream)\n",
    "\n",
    "                gyr_mag_800 = smooth(gyr_mag, fastSize)\n",
    "                gyr_mag_8000 = smooth(gyr_mag, slowSize)\n",
    "                \n",
    "                gyr_intersections, dont_care = segmentationUsingTwoMovingAverage(gyr_mag_8000, gyr_mag_800, 0, 4)\n",
    "                gyr_intersections = filterDuration(gyr_intersections, t)\n",
    "                gyr_intersections = filterRollPitch(gyr_intersections, roll, pitch)\n",
    "\n",
    "                all_features = computeWindowFeatures(gyr_intersections, gyr_mag, roll, pitch, yaw, Ax, Ay, Az, t)\n",
    "\n",
    "                st = [f[0] for f in all_features]\n",
    "                et = [f[0]+f[1] for f in all_features]\n",
    "                labels = [0]*len(st)\n",
    "\n",
    "                for k in range(len(st)):\n",
    "                    labels[k] = getLabel(st[k], et[k], epi_st, epi_et, puff_times)\n",
    "                    if labels[k] != -1:\n",
    "                        Xs.append(all_features[k][1:])\n",
    "                        if labels[k] == 0:\n",
    "                            Ys.append('non-puff')\n",
    "                        else:\n",
    "                            Ys.append('puff')\n",
    "\n",
    "                print(len(Xs))\n",
    "    #             print(sum(Ys))     \n",
    "        \n",
    "    print(len(Ys))\n",
    "#     print(sum(Ys))\n",
    "    print(nSample)\n",
    "    \n",
    "#     print(Xs)\n",
    "#     print(Ys)\n",
    "\n",
    "    Xs = np.array(Xs)\n",
    "    Ys = np.array([Ys])\n",
    "    M = np.concatenate((Xs, Ys.T), axis=1)\n",
    "\n",
    "    df = pd.DataFrame(M)\n",
    "    feature_name = ['duration', 'roll_mean', 'roll_median', 'roll_sd', 'roll_quartile', 'pitch_mean', 'pitch_median', 'pitch_sd', 'pitch_quartile', 'yaw_mean', 'yaw_median', 'yaw_sd', 'yaw_quartile', 'gyro_mean', 'gyro_median', 'gyro_sd', 'gyro_quartile', 'label(1:puff; 0:non-puff)']\n",
    "    df.to_csv(\"file_path.csv\", header=feature_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 2, 3, 4]\n",
      "6\n",
      "[[1, 2, 3], [2, 3, 4]]\n",
      "3\n",
      "2\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "A=[1, 2,3 ]\n",
    "B=[2, 3, 4]\n",
    "C=[]\n",
    "C.extend(A)\n",
    "C.extend(B)\n",
    "print(C)\n",
    "print(len(C))\n",
    "C=[]\n",
    "C.append(A)\n",
    "C.append(B)\n",
    "print(C)\n",
    "print(C[0][2])\n",
    "print(len(C))\n",
    "\n",
    "for i in range(7, 10):\n",
    "    print(i)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.73205080757\n",
      "1.41421356237\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "print(norm([1, 1, 1]))\n",
    "print(norm([1, 1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
